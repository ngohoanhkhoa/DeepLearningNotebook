{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark NLP: Natural Language Processing with Disaster Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use [Spark NLP](https://nlp.johnsnowlabs.com/) for Bert sentence embeddings and a classification DNN ([ClassifierDLApproach](https://nlp.johnsnowlabs.com/api/python/reference/autosummary/sparknlp.annotator.ClassifierDLApproach.html)). This experiment is done by using [Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/quick_start_google_colab.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "spark = sparknlp.start(gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPath = 'nlp-getting-started/train.csv'\n",
    "testPath = 'nlp-getting-started/test.csv'\n",
    "\n",
    "trainData = spark.read.format('csv').options(header='true', inferSchema='true', multiLine=True).load(trainPath)\n",
    "testData = spark.read.format('csv').options(header='true', inferSchema='true', multiLine=True).load(testPath)\n",
    "\n",
    "print('Number of row in Training:', trainData.count())\n",
    "print('Number of row in Test:    ', testData.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentAssembler = DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\")\n",
    "sentenceDetector = SentenceDetector().setInputCols([\"document\"]).setOutputCol(\"sentence\")\n",
    "sentenceEmbeddings = BertSentenceEmbeddings.pretrained(\"sent_bert_base_cased\", \"en\").setInputCols(\"sentence\").setOutputCol(\"sentenceEmbeddings\")\n",
    "embeddingsFinisher = EmbeddingsFinisher().setInputCols([\"sentenceEmbeddings\"]).setOutputCols(\"finishedEmbeddings\").setOutputAsVector(True)\n",
    "\n",
    "pipeline = Pipeline().setStages([documentAssembler,sentenceDetector,sentenceEmbeddings,embeddingsFinisher])\n",
    "\n",
    "model = pipeline.fit(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataSnlp = model.transform(trainData)\n",
    "testDataSnlp = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierDL = ClassifierDLApproach() \\\n",
    ".setInputCols([\"sentenceEmbeddings\"]) \\\n",
    ".setOutputCol(\"labelFull\") \\\n",
    ".setLabelColumn(\"target\") \\\n",
    ".setBatchSize(64) \\\n",
    ".setMaxEpochs(20) \\\n",
    ".setLr(5e-3) \\\n",
    ".setDropout(0.5)\\\n",
    ".setEnableOutputLogs(True)\n",
    "\n",
    "classifierDLModel = classifierDL.fit(trainDataSnlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started - epochs: 20 - learning_rate: 0.005 - batch_size: 64 - training_examples: 13341 - classes: 2\n",
      "Epoch 0/20 - 0.49s - loss: 125.230545 - acc: 0.7007471 - batches: 209\n",
      "Epoch 1/20 - 0.34s - loss: 115.544014 - acc: 0.7358437 - batches: 209\n",
      "Epoch 2/20 - 0.34s - loss: 114.46812 - acc: 0.7435811 - batches: 209\n",
      "Epoch 3/20 - 0.33s - loss: 113.75002 - acc: 0.74919957 - batches: 209\n",
      "Epoch 4/20 - 0.34s - loss: 113.10281 - acc: 0.7550745 - batches: 209\n",
      "Epoch 5/20 - 0.35s - loss: 112.81218 - acc: 0.760048 - batches: 209\n",
      "Epoch 6/20 - 0.33s - loss: 112.79334 - acc: 0.7641045 - batches: 209\n",
      "Epoch 7/20 - 0.37s - loss: 112.8797 - acc: 0.767244 - batches: 209\n",
      "Epoch 8/20 - 0.34s - loss: 112.86142 - acc: 0.76996386 - batches: 209\n",
      "Epoch 9/20 - 0.34s - loss: 112.65094 - acc: 0.77289355 - batches: 209\n",
      "Epoch 10/20 - 0.34s - loss: 112.2948 - acc: 0.77552277 - batches: 209\n",
      "Epoch 11/20 - 0.34s - loss: 112.11395 - acc: 0.7776261 - batches: 209\n",
      "Epoch 12/20 - 0.36s - loss: 111.9319 - acc: 0.7798797 - batches: 209\n",
      "Epoch 13/20 - 0.34s - loss: 111.74605 - acc: 0.7816075 - batches: 209\n",
      "Epoch 14/20 - 0.35s - loss: 111.56647 - acc: 0.783185 - batches: 209\n",
      "Epoch 15/20 - 0.34s - loss: 111.35628 - acc: 0.7839362 - batches: 209\n",
      "Epoch 16/20 - 0.34s - loss: 111.02795 - acc: 0.78566396 - batches: 209\n",
      "Epoch 17/20 - 0.33s - loss: 110.67951 - acc: 0.7874824 - batches: 209\n",
      "Epoch 18/20 - 0.33s - loss: 110.32417 - acc: 0.78898484 - batches: 209\n",
      "Epoch 19/20 - 0.39s - loss: 109.93248 - acc: 0.7905028 - batches: 209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "with open(\"ClassifierDLApproach_0da7e830db4e.log\", \"r\") as log_file :\n",
    "    print(log_file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of classifierDLModel.transform() need several transformations to get the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionTest = classifierDLModel.transform(testDataSnlp)\n",
    "predictionTest = Finisher().setInputCols(\"labelFull\").setOutputCols(\"labelSimple\").transform(predictionTest)\n",
    "predictionTest = predictionTest.withColumn(\"labelSimple\", F.col(\"labelSimple\").cast(\"array<integer>\"))\n",
    "predictionTest = predictionTest.selectExpr('id', \"AGGREGATE(labelSimple, 0, (acc, x) -> acc + x) as label\")\n",
    "predictionTest = predictionTest.withColumn('labelFinal', F.when(F.col(\"label\") >= 1, 1).otherwise(0))\n",
    "predLabelTest = np.array(predictionTest.select('labelFinal').collect()).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The score of test set is 0.80355.**  \n",
    "We can see an improvement by using BERT/NNs compared with the score 0.77536 of [our previous notebook](https://deepnote.com/project/Pyspark-for-Natural-Language-Processing-with-Disaster-Tweets--dn4DX33Tem9ogzvD8t7Eg).\n",
    "Note that the architecture of ClassifierDLApproach is still not published."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
